import os
import streamlit as st
import numpy as np 
from PIL import Image
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
import platform

# --- CSS G√ìTICO (Paleta Arcano-Escarlata) ---
gothic_css_variant = """
<style>
/* Paleta base: Fondo #111111, Texto #E0E0E0 (Pergamino ligero), Acento #5A4832 (Bronce/Metal), Sangre #A50000 */
.stApp {
    background-color: #111111;
    color: #E0E0E0;
    font-family: 'Georgia', serif;
}

/* T√≠tulo Principal (h1) */
h1 {
    color: #A50000; /* Rojo sangre */
    text-shadow: 3px 3px 8px #000000;
    font-size: 3.2em; 
    border-bottom: 5px solid #5A4832; /* Borde Bronce */
    padding-bottom: 10px;
    margin-bottom: 30px;
    text-align: center;
    letter-spacing: 2px;
}

/* Subt√≠tulos (h2, h3): √ânfasis en el bronce */
h2, h3 {
    color: #C0C0C0; /* Plata/gris claro */
    border-left: 5px solid #5A4832;
    padding-left: 10px;
    margin-top: 25px;
}

/* Input y Camera (El Papiro de Inscripci√≥n) */
div[data-testid="stTextInput"], div[data-testid="stTextarea"], .stFileUploader, .stCameraInput {
    background-color: #1A1A1A;
    border: 1px solid #5A4832;
    padding: 10px;
    border-radius: 5px;
    color: #F5F5DC;
}

/* Dataframe (No hay en este script, pero por consistencia) */
div[data-testid="stDataFrame"] table {
    background-color: #1A1A1A;
    border: 1px solid #5A4832;
    color: #E0E0E0;
}
div[data-testid="stDataFrame"] thead tr th {
    background-color: #2A2A2A !important;
    color: #A50000 !important;
}

/* Texto de Alertas (Revelaciones) */
.stSuccess { background-color: #20251B; color: #F5F5DC; border-left: 5px solid #5A4832; }
.stInfo { background-color: #1A1A25; color: #F5F5DC; border-left: 5px solid #5A4832; }
.stWarning { background-color: #352A1A; color: #F5F5DC; border-left: 5px solid #A50000; }

/* Streamlit Sidebar Background */
.css-1d3w5rq {
    background-color: #202020;
}
</style>
"""
st.markdown(gothic_css_variant, unsafe_allow_html=True)

# Configuraci√≥n de p√°gina Streamlit
st.set_page_config(
    page_title="El C√≥dice del Or√°culo Documental",
    page_icon="üìú",
    layout="wide"
)

# App title and presentation
st.title('üìú Generaci√≥n Aumentada por Recuperaci√≥n (RAG)')
st.write(f"Versi√≥n del Scriptorium (Python): **{platform.python_version()}**")

# Load and display image 
try:
    # Nota: Este archivo ('Chat_pdf.png') debe estar presente en el entorno de ejecuci√≥n.
    image = Image.open('Chat_pdf.png')
    st.image(image, width=350, caption="El Sello de la Sabidur√≠a")
except Exception as e:
    st.warning(f"No se pudo cargar el Sello de la Sabidur√≠a ('Chat_pdf.png'). {e}")

# Sidebar information
with st.sidebar:
    st.subheader("El Escriba del Conocimiento Oculto")
    st.markdown("""
    Este Agente te permitir√° interrogar el conocimiento cifrado en el **Papiro Digital (PDF)** cargado.
    Requiere la **Esencia Vital de OpenAI (API Key)** para invocar sus poderes.
    """)

# Get API key from user
ke = st.text_input('Ingresa tu Clave de Esencia Vital (OpenAI API Key)', type="password")
if ke:
    os.environ['OPENAI_API_KEY'] = ke
else:
    st.warning("‚ö†Ô∏è Introduce tu Clave de Esencia Vital (OpenAI API Key) para activar el C√≥dice.")

# PDF uploader
pdf = st.file_uploader("Carga el Papiro Digital (Archivo PDF)", type="pdf")

# Process the PDF if uploaded
if pdf is not None and ke:
    try:
        # Extraer el texto del Papiro Digital
        with st.spinner("Extracto de Runas y S√≠mbolos del Papiro..."):
            pdf_reader = PdfReader(pdf)
            text = ""
            for page in pdf_reader.pages:
                extracted_text = page.extract_text()
                if extracted_text:
                    text += extracted_text
                
            if not text:
                 st.error("El Papiro Digital no contiene texto legible (o est√° vac√≠o).")
                 st.stop()
        
        st.info(f"Papiro Descifrado: **{len(text)}** caracteres")
        
        # --- L√≥gica de Almacenamiento y Recuperaci√≥n (FAISS en session_state) ---
        # Si la base de conocimiento no existe o el PDF ha cambiado, la creamos
        if 'knowledge_base' not in st.session_state or st.session_state.get('pdf_name') != pdf.name:
            
            # 1. Dividir el texto en fragmentos (Ritos de Fragmentaci√≥n)
            with st.spinner("Fragmentando el C√≥dice para la Memoria Arcana..."):
                text_splitter = CharacterTextSplitter(
                    separator="\n",
                    chunk_size=500,
                    chunk_overlap=20,
                    length_function=len
                )
                chunks = text_splitter.split_text(text)
            
            st.success(f"C√≥dice Fragmentado en **{len(chunks)}** secciones de Memoria")

            # 2. Crear embeddings y base de conocimiento (El Altar de la Memoria)
            with st.spinner("Inscribiendo Fragmentos en el Altar de la Memoria (FAISS)..."):
                embeddings = OpenAIEmbeddings()
                knowledge_base = FAISS.from_texts(chunks, embeddings)
                st.session_state.knowledge_base = knowledge_base
                st.session_state.pdf_name = pdf.name
        
        else:
            # Si ya est√° en la sesi√≥n, la recuperamos
            knowledge_base = st.session_state.knowledge_base

        st.success("Altar de la Memoria (FAISS) Erigido exitosamente.")

        # Interfaz de pregunta del usuario
        st.subheader("Escribe el Interrogatorio sobre el Papiro")
        user_question = st.text_area(" ", placeholder="¬øQu√© verdad oculta este pergamino? Escribe tu pregunta aqu√≠...", key="user_q")
        
        # Procesa la pregunta cuando se env√≠a
        if user_question:
            with st.spinner("Invocando el Or√°culo Aumentado..."):
                # B√∫squeda de documentos
                docs = knowledge_base.similarity_search(user_question)
                
                # Inicializar el modelo LLM
                llm = OpenAI(temperature=0, model_name="gpt-4o")
                
                # Cargar la cadena de Preguntas y Respuestas
                chain = load_qa_chain(llm, chain_type="stuff")
                
                # Ejecutar la cadena
                response = chain.run(input_documents=docs, question=user_question)
            
            # Mostrar la respuesta
            st.markdown("### üó£Ô∏è Respuesta del Or√°culo:")
            st.markdown(response)
                
    except Exception as e:
        st.error(f"Error Cr√≠tico al procesar el Papiro: {str(e)}")
        # Mostrar el error detallado para depuraci√≥n
        import traceback
        st.error(traceback.format_exc())
        
elif pdf is not None and not ke:
    st.warning("El Papiro est√° cargado, pero la Clave de Esencia Vital es necesaria.")
else:
    st.info("Por favor, carga un Papiro Digital (PDF) y proporciona la Clave de Esencia Vital para comenzar la Interrogaci√≥n.")

# Informaci√≥n adicional y pie de p√°gina
st.markdown("---")
st.caption("""
**Notas del Erudito**: Este C√≥dice utiliza los principios de RAG (Generaci√≥n Aumentada por Recuperaci√≥n) con LangChain y OpenAI.
""")

